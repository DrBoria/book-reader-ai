import { OpenAI } from "openai";
import { StateGraph, START, END, BaseMessage, addMessages, GraphState } from "../langgraph/StateGraph";
import { Tag, BookContent, TaggedContent, AgentState } from "../types";

// Define the agent's state structure following LangGraph patterns
interface BookTaggingState extends GraphState {
  messages: BaseMessage[];
  currentBook: BookContent | null;
  tags: Tag[];
  taggedContent: TaggedContent[];
  isProcessing: boolean;
  currentStep: string;
  userQuery: string;
}

export class LMStudioBookTaggingAgent {
  private openai: OpenAI;
  private graph: any;
  private currentState: BookTaggingState;
  private modelName: string;

  constructor(lmStudioHost = "http://192.168.1.178:1234", modelName = "deepseek/deepseek-r1-0528-qwen3-8b") {
    // Configure OpenAI client to use LM Studio
    // Ensure proper URL formatting - remove trailing slash if present
    const cleanHost = lmStudioHost.replace(/\/$/, '');
    this.openai = new OpenAI({ 
      baseURL: `${cleanHost}/v1`,
      apiKey: "lm-studio", // LM Studio –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–π API –∫–ª—é—á
      dangerouslyAllowBrowser: true
    });
    this.modelName = modelName;
    
    this.currentState = {
      messages: [],
      currentBook: null,
      tags: this.getDefaultTags(),
      taggedContent: [],
      isProcessing: false,
      currentStep: "ready",
      userQuery: ""
    };
    
    this.graph = this.createGraph();
  }

  private getDefaultTags(): Tag[] {
    return [
      { id: "time", name: "–í—Ä–µ–º—è", description: "–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∏ –ø–µ—Ä–∏–æ–¥—ã", color: "#3B82F6", type: "default" },
      { id: "people", name: "–õ—é–¥–∏", description: "–£–ø–æ–º–∏–Ω–∞–µ–º—ã–µ –ª–∏—Ü–∞ –∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏", color: "#EF4444", type: "default" },
      { id: "theme", name: "–¢–µ–º–∞", description: "–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏", color: "#10B981", type: "default" },
      { id: "location", name: "–õ–æ–∫–∞—Ü–∏—è", description: "–£–ø–æ–º–∏–Ω–∞–µ–º—ã–µ –º–µ—Å—Ç–∞", color: "#F59E0B", type: "default" }
    ];
  }

  private createGraph() {
    // Create StateGraph with proper state definition following LangGraph patterns
    const workflow = new StateGraph<BookTaggingState>({
      messages: {
        reducer: addMessages,
        default: () => []
      },
      currentBook: {
        reducer: (current: BookContent | null, update: BookContent | null) => update ?? current,
        default: () => null
      },
      tags: {
        reducer: (current: Tag[], update: Tag[]) => update.length > 0 ? update : current,
        default: () => this.getDefaultTags()
      },
      taggedContent: {
        reducer: (current: TaggedContent[], update: TaggedContent[]) => [...current, ...update],
        default: () => []
      },
      isProcessing: {
        reducer: (current: boolean, update: boolean) => update,
        default: () => false
      },
      currentStep: {
        reducer: (current: string, update: string) => update || current,
        default: () => "ready"
      },
      userQuery: {
        reducer: (current: string, update: string) => update || current,
        default: () => ""
      }
    });

    // Add nodes (functions that process the state)
    workflow.addNode("processBook", this.processBookNode.bind(this));
    workflow.addNode("tagContent", this.tagContentNode.bind(this));
    workflow.addNode("answerQuery", this.answerQueryNode.bind(this));
    workflow.addNode("complete", this.completeNode.bind(this));

    // Add edges following LangGraph routing patterns
    workflow.addEdge(START, "processBook");
    
    workflow.addConditionalEdge(
      "processBook",
      this.routeAfterProcessing.bind(this),
      {
        "tag": "tagContent",
        "query": "answerQuery", 
        "complete": "complete"
      }
    );
    
    workflow.addEdge("tagContent", "complete");
    workflow.addEdge("answerQuery", "complete");
    workflow.addEdge("complete", END);

    return workflow.compile();
  }

  // Node: Process PDF book (following LangGraph node pattern)
  private async processBookNode(state: BookTaggingState): Promise<Partial<BookTaggingState>> {
    if (state.currentBook && state.currentStep === "processBook") {
      return {
        messages: [{
          role: "assistant",
          content: "üìö –ö–Ω–∏–≥–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –ì–æ—Ç–æ–≤ –∫ –∞–Ω–∞–ª–∏–∑—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å –ø–æ–º–æ—â—å—é DeepSeek R1.",
          timestamp: new Date()
        }],
        isProcessing: false,
        currentStep: "tag"
      };
    }
    return { currentStep: "ready" };
  }

  // Node: Tag content using DeepSeek R1 via LM Studio
  private async tagContentNode(state: BookTaggingState): Promise<Partial<BookTaggingState>> {
    if (!state.currentBook) {
      return { 
        messages: [{
          role: "assistant",
          content: "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π –∫–Ω–∏–≥–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
          timestamp: new Date()
        }]
      };
    }

    const newTaggedContent: TaggedContent[] = [];
    
    // Process each page following the tagging workflow
    let processedPages = 0;
    for (const page of state.currentBook.pages) {
      try {
        const pageTaggedContent = await this.tagPageContent(
          page.text, 
          page.pageNumber, 
          state.tags
        );
        newTaggedContent.push(...pageTaggedContent);
        processedPages++;
        
        // Progress feedback
        if (processedPages % 5 === 0) {
          console.log(`–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: ${processedPages}/${state.currentBook.pages.length}`);
        }
      } catch (error) {
        console.error(`–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ${page.pageNumber}:`, error);
      }
    }

    return {
      taggedContent: newTaggedContent,
      messages: [{
        role: "assistant",
        content: `üè∑Ô∏è –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ ${newTaggedContent.length} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ ${state.currentBook.pages.length} —Å—Ç—Ä–∞–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é DeepSeek R1.`,
        timestamp: new Date()
      }],
      currentStep: "complete"
    };
  }

  // Node: Answer user queries using DeepSeek R1 via LM Studio
  private async answerQueryNode(state: BookTaggingState): Promise<Partial<BookTaggingState>> {
    if (!state.userQuery || !state.currentBook) {
      return {
        messages: [{
          role: "assistant",
          content: "‚ùì –ù–µ—Ç –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ –∫–Ω–∏–≥–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
          timestamp: new Date()
        }]
      };
    }

    const relevantContent = this.findRelevantContent(state.userQuery, state.taggedContent);
    const answer = await this.generateAnswer(state.userQuery, relevantContent);

    return {
      messages: [
        {
          role: "user",
          content: state.userQuery,
          timestamp: new Date()
        },
        {
          role: "assistant", 
          content: answer,
          timestamp: new Date()
        }
      ],
      userQuery: "",
      currentStep: "complete"
    };
  }

  // Node: Complete processing
  private async completeNode(state: BookTaggingState): Promise<Partial<BookTaggingState>> {
    return {
      isProcessing: false,
      currentStep: "ready"
    };
  }

  // Router function for conditional edges (LangGraph pattern)
  private routeAfterProcessing(state: BookTaggingState): string {
    if (state.userQuery) return "query";
    if (state.currentStep === "tag") return "tag";
    return "complete";
  }

  // AI-powered tagging using DeepSeek R1 via LM Studio
  private async tagPageContent(
    text: string, 
    pageNumber: number, 
    tags: Tag[]
  ): Promise<TaggedContent[]> {
    const prompt = this.buildTaggingPrompt(text, tags);
    
    try {
      const response = await this.openai.chat.completions.create({
        model: this.modelName,
        messages: [{ 
          role: "user", 
          content: prompt 
        }],
        temperature: 0.1, // –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        max_tokens: 1000,
        top_p: 0.9
      });

      const content = response.choices[0].message.content || "";
      return this.parseTaggingResponse(content, text, pageNumber);
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å DeepSeek R1 (LM Studio):", error);
      return [];
    }
  }

  private buildTaggingPrompt(text: string, tags: Tag[]): string {
    const tagDescriptions = tags.map(tag => 
      `${tag.name}: ${tag.description}`
    ).join(", ");

    return `<thinking>
–ú–Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å–ª–µ–¥—É—é—â–∏–º —Ç–µ–≥–∞–º: ${tagDescriptions}.

–Ø –¥–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–≥–∞ –∏ –æ—Ü–µ–Ω–∏—Ç—å –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.
</thinking>

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–≥–∞–º: ${tagDescriptions}.

–¢–µ–∫—Å—Ç: "${text}"

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
[
  {
    "tagId": "id_—Ç–µ–≥–∞",
    "content": "—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞",
    "relevance": 0.8,
    "context": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"
  }
]

–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - —Ç–æ–ª—å–∫–æ JSON –º–∞—Å—Å–∏–≤.`;
  }

  private parseTaggingResponse(response: string, originalText: string, pageNumber: number): TaggedContent[] {
    try {
      // Extract JSON from response (DeepSeek might add extra text)
      const jsonMatch = response.match(/\[[\s\S]*\]/);
      if (!jsonMatch) {
        console.warn("–ù–µ –Ω–∞–π–¥–µ–Ω JSON –≤ –æ—Ç–≤–µ—Ç–µ DeepSeek");
        return [];
      }

      const cleanedResponse = jsonMatch[0];
      const parsed = JSON.parse(cleanedResponse);
      
      if (!Array.isArray(parsed)) {
        console.warn("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º:", parsed);
        return [];
      }

      return parsed.map((item: any) => ({
        id: Math.random().toString(36),
        tagId: item.tagId,
        content: item.content,
        pageNumber,
        relevance: item.relevance || 0.5,
        context: item.context,
        originalText
      }));
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ DeepSeek:", error);
      // Fallback –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
      return this.fallbackTagExtraction(response, originalText, pageNumber);
    }
  }

  private fallbackTagExtraction(response: string, originalText: string, pageNumber: number): TaggedContent[] {
    // –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –µ—Å–ª–∏ JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è
    const results: TaggedContent[] = [];
    
    // –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤—Ä–µ–º–µ–Ω–∏
    const timePatterns = [
      /\b\d{4}\s*–≥\.?/g, // –≥–æ–¥—ã
      /\b\d{1,2}\s*(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)/gi,
      /\b(–≤\s+—Ç–æ\s+–≤—Ä–µ–º—è|—Ç–æ–≥–¥–∞|–ø–æ–∑–∂–µ|—Ä–∞–Ω—å—à–µ|–ø–æ—Å–ª–µ|–¥–æ)/gi
    ];
    
    timePatterns.forEach(pattern => {
      const matches = originalText.match(pattern);
      if (matches) {
        matches.forEach(match => {
          results.push({
            id: Math.random().toString(36),
            tagId: "time",
            content: match,
            pageNumber,
            relevance: 0.6,
            context: "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–æ",
            originalText
          });
        });
      }
    });
    
    return results.slice(0, 3); // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
  }

  private findRelevantContent(query: string, taggedContent: TaggedContent[]): TaggedContent[] {
    const lowerQuery = query.toLowerCase();
    return taggedContent.filter(content =>
      content.content.toLowerCase().includes(lowerQuery) ||
      content.context?.toLowerCase().includes(lowerQuery)
    ).slice(0, 10); // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  }

  private async generateAnswer(query: string, content: TaggedContent[]): Promise<string> {
    const contextText = content.map(c => 
      `–°—Ç—Ä–∞–Ω–∏—Ü–∞ ${c.pageNumber}: "${c.content}" (–ö–æ–Ω—Ç–µ–∫—Å—Ç: ${c.context})`
    ).join("\n");

    const prompt = `<thinking>
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å: "${query}"

–£ –º–µ–Ω—è –µ—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –∫–Ω–∏–≥–∏:
${contextText}

–ú–Ω–µ –Ω—É–∂–Ω–æ –¥–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, —É–∫–∞–∑–∞–≤ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Ü–∏—Ç–∞—Ç—ã.
</thinking>

–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–Ω–∏–≥–∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: "${query}"

–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:
${contextText}

–î–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Ü–∏—Ç–∞—Ç –∏–∑ –∫–Ω–∏–≥–∏.`;

    try {
      const response = await this.openai.chat.completions.create({
        model: this.modelName,
        messages: [{ role: "user", content: prompt }],
        temperature: 0.3,
        max_tokens: 1500,
        top_p: 0.9
      });

      return response.choices[0].message.content || "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.";
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —Å DeepSeek R1 (LM Studio):", error);
      return "‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ LM Studio –∑–∞–ø—É—â–µ–Ω –∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.";
    }
  }

  // Check if LM Studio and model are available
  async checkModelAvailability(): Promise<boolean> {
    try {
      const response = await this.openai.models.list();
      return response.data.some(model => model.id.includes('deepseek'));
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LM Studio:", error);
      return false;
    }
  }

  // Public API methods
  async processBook(content: BookContent): Promise<void> {
    try {
      const result = await this.graph.invoke({
        currentBook: content,
        isProcessing: true,
        currentStep: "processBook"
      });
      
      this.currentState = { ...this.currentState, ...result };
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥–∏:", error);
      this.currentState.isProcessing = false;
    }
  }

  async answerQuestion(question: string): Promise<string> {
    try {
      const result = await this.graph.invoke({
        ...this.currentState,
        userQuery: question,
        currentStep: "query"
      });
      
      this.currentState = { ...this.currentState, ...result };
      
      // Extract the last assistant message
      const assistantMessages = this.currentState.messages.filter(m => m.role === "assistant");
      const lastMessage = assistantMessages[assistantMessages.length - 1];
      
      return lastMessage?.content || "–û—Ç–≤–µ—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.";
    } catch (error) {
      console.error("–û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å:", error);
      return "‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞.";
    }
  }

  addCustomTag(tag: Omit<Tag, "id" | "type">): string {
    const newTag: Tag = {
      ...tag,
      id: Math.random().toString(36),
      type: "custom"
    };
    this.currentState.tags.push(newTag);
    return newTag.id;
  }

  getState(): AgentState {
    return {
      messages: this.currentState.messages.map(m => ({
        id: Math.random().toString(36),
        type: m.role === "user" ? "user" : "assistant",
        content: m.content,
        timestamp: m.timestamp || new Date()
      })),
      currentBook: this.currentState.currentBook,
      tags: this.currentState.tags,
      taggedContent: this.currentState.taggedContent,
      isProcessing: this.currentState.isProcessing,
      currentStep: this.currentState.currentStep
    };
  }

  getContentByTag(tagId: string): TaggedContent[] {
    return this.currentState.taggedContent.filter(content => content.tagId === tagId);
  }
}
